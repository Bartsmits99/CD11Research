{"backend_state":"running","kernel":"python3","kernel_state":"idle","kernel_usage":{"cpu":0,"memory":83542016},"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"}},"type":"settings"}
{"cell_type":"code","exec_count":0,"id":"af1e92","input":"","pos":11,"type":"cell"}
{"cell_type":"code","exec_count":10,"id":"a7a172","input":"# create neural network   \nNN = NeuralNetwork(inputs, outputs)\n# train neural network\nNN.train()\n","pos":6,"type":"cell"}
{"cell_type":"code","exec_count":11,"id":"24b786","input":"# create two new examples to predict                                   \nexample = np.array([[1, 1, 0]])\nexample_2 = np.array([[0, 1, 1]])\nexample_3= np.array([[0, 0, 1]])\n# print the predictions for both examples                                   \nprint(NN.predict(example))\nprint(NN.predict(example_2))\nprint(NN.predict(example_3))","output":{"0":{"name":"stdout","output_type":"stream","text":"[[0.99992715]]\n[[8.42790414e-05]]\n[[0.00909743]]\n"}},"pos":8,"type":"cell"}
{"cell_type":"code","exec_count":12,"id":"b367ab","input":"# plot the error over the entire training duration\nplt.figure(figsize=(15,5))\nplt.plot(NN.epoch_list, NN.error_history)\nplt.xlabel('Epoch')\nplt.ylabel('Error')\nplt.show()","output":{"0":{"data":{"image/png":"0d1ad8eaf1fcb340cefaf75588fc4d7530c8a6f2","text/plain":"<Figure size 1080x360 with 1 Axes>"},"exec_count":12,"metadata":{"image/png":{"height":316,"width":894},"needs_background":"light"},"output_type":"execute_result"}},"pos":10,"type":"cell"}
{"cell_type":"code","exec_count":3,"id":"fa66c8","input":"import numpy as np # helps with the math\nimport matplotlib.pyplot as plt # to plot error during training\n\n# input data\ninputs = np.array([[0, 1, 0],\n                   [0, 1, 1],\n                   [0, 0, 0],\n                   [1, 0, 0],\n                   [1, 1, 1],\n                   [1, 0, 1],\n                   [0, 0, 1]])\n# output data\noutputs = np.array([[0], [0], [0], [1], [1], [1],[0]])\n","pos":2,"scrolled":true,"type":"cell"}
{"cell_type":"code","exec_count":9,"id":"2cf68f","input":"# create NeuralNetwork class\nclass NeuralNetwork:\n\n    # intialize variables in class\n    def __init__(self, inputs, outputs):\n        self.inputs  = inputs\n        self.outputs = outputs\n        # initialize weights as .50 for simplicity\n        self.weights = np .array([[.50], [.50], [.50]])\n        self.error_history = []\n        self.epoch_list = []\n\n    #activation function ==> S(x) = 1/1+e^(-x)\n    def sigmoid(self, x, deriv=False):\n        if deriv == True:\n            return x * (1 - x)\n        return 1 / (1 + np.exp(-x))\n\n    # data will flow through the neural network.\n    def feed_forward(self):\n        self.hidden = self.sigmoid(np.dot(self.inputs, self.weights))\n\n    # going backwards through the network to update weights\n    def backpropagation(self):\n        self.error  = self.outputs - self.hidden\n        delta = self.error * self.sigmoid(self.hidden, deriv=True)\n        self.weights += np.dot(self.inputs.T, delta)\n\n    # train the neural net for 25,000 iterations\n    def train(self, epochs=25000):\n        for epoch in range(epochs):\n            # flow forward and produce an output\n            self.feed_forward()\n            # go back though the network to make corrections based on the output\n            self.backpropagation()    \n            # keep track of the error history over each epoch\n            self.error_history.append(np.average(np.abs(self.error)))\n            self.epoch_list.append(epoch)\n\n    # function to predict output on new and unseen input data                               \n    def predict(self, new_input):\n        prediction = self.sigmoid(np.dot(new_input, self.weights))\n        return prediction\n\n\n","pos":4,"type":"cell"}
{"cell_type":"raw","id":"0c613d","input":"This is where the error is plotted against the iterations. As you can see the error reduces quite quickly ","pos":9,"type":"cell"}
{"cell_type":"raw","id":"4c1d89","input":"Now an object is created using the neural network class. This object is named NN. It also uses NN.train() to \"activate\" that part in the class.","pos":5,"type":"cell"}
{"cell_type":"raw","id":"b2d54f","input":"Then a class is made in which all the inputs and outputs are recalled and named. Im gonna describe every def function now:\n\ndef __init__(self, inputs, outputs): This function names the inputs and outputs provided earlier. Moreover the weights of each variable is given which will be changing later when the programm is training. Also 2 lists are made which we are going to use later to keep track of the error\n\ndef sigmoid(self, x, deriv=False): The activation function is created which in this case is a Sigmoid function. This sigmoid function converts values such that it outputs a number between 0 and 1. Also the derivative of this sigmoid function is described which we will need later on during backpropagation.\n\ndef feed_forward(self): Now the feed forward, This feedforward will feed the input and weights into the sigmoid function that was defined previously. The dot ptoduct of the inputs and weights is the value x in this case. This is bascially the result that the network created but it is obviously wrong as the weights have not been adjusted yet. As it uses the sigmoid function the result is a number between 0 and 1\n\ndef backpropagation(self): This is the code that the network uses to learn. First it calculates the error which is the difference between the output that was provided in def __init__ and the result from def feed_forward. This error is multiplied with the derivative of the sigmoid function to get delta. The actual value that needs to be added to the old weight is the dot product of delta and the transpose of the input matrix. This is added to the old weight to obtain the new weight. The formula is also put in the scratch overleaf if it looks a bit messy here. There is also a description on there. \n\ndef train(self, epochs=25000): Now the network is trained using this definition. It is basically a loop of 25000 iterations (changeable) of feed forward and backpropagation. Also the lists made in def __init__ are used to keep track of the error. This will later be projected in a graph to show the error over iterations. After this has run the weights are adjusted and the program can produce accurate results.\n\ndef predict(self, new_input): This piece of code is used to make an prediction of a new input (not something from the training set). It also returns this answer.\n\nThis is what is done in the neural network class\n\n","pos":3,"type":"cell"}
{"cell_type":"raw","id":"d2d662","input":"This is an example code of how a supervised learning neural network programm works. The input for this neural network are multiple matrixes consisting of 1's and 0's. The output should be the number in the first row of the matrix. This neural network programm will learn this. ","pos":0,"type":"cell"}
{"cell_type":"raw","id":"d35cd5","input":"First a training data set is imported. This is described as inputs and outputs where both input and output are already known. ","pos":1,"type":"cell"}
{"cell_type":"raw","id":"e42250","input":"Now some random examples are created to see if the code actually works. It prints out a value between 0 and 1. A number close to 0 is 0 and a number close to 1 is 1. As you can see the answer are correct because the result for the first answer is close to 1 and the answer for the second and third are close to 0.","pos":7,"type":"cell"}
{"id":0,"time":1584633662499,"type":"user"}
{"last_load":1584633377520,"type":"file"}